---
title: "Project 2"
author: "Jennifer Nguyen (JNN497)"
date: "4/23/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Introduction
I chose the cancer dataset from the survival package. This dataset contains information pertaining to the survival of lung cancer patients from the North Central Cancer Treatmnet Group. Originally, I chose 6 variables from the dataset. However, I had to mutate certain variables in order to get binary and categorical variables. I also had to change the levels of the binary variable from "1" and "2" to "0" and "1" for later use. The resulting dataset I used had 8 variables.  

In this dataset, the binary variable is the sex variable and has two levels, male (1) or female (2). I mutated the sex variable into a categorical variable called "sex_cat" that had "male" and "female" for their respective observations. Another binary variable is the status variable, and it holds the censoring status of the patient as either 0 (censored) or 1 (dead). A categorical variable was created from the binary status variable named "status_cat" that has the levels of "censored" and "dead" to indicate the respective status of the patient. The numeric variables are the ph.ecog variable, the ph.karno variable, the time variable, and the age variable. The ph.ecog variable measures the status of the patient from 0 to 4, with 0 being asymptomatic and 4 being bedbound. The ph.karno variable is the Karnofsky performance score on a scale from 0 to 100 rated by a physician, with 0 being bad and 100 being good. The time variable is the survival time in days of the patient. The age variable tells us the age of the patient. There are 226 observations in my dataset.

##1. MANOVA
```{r}
library(tidyverse)
library(survival)
cancer <- cancer  %>% select(sex, status, age, time, ph.ecog, ph.karno) %>% na.omit %>% 
  mutate(status_cat = case_when(status==1 ~ "censored", status==2 ~ "dead"),
         status = as.numeric(case_when(status==1 ~ "0", status==2 ~ "1")), 
         sex_cat = case_when(sex==1 ~ "male", sex ==2 ~ "female")) %>%
  select(sex, sex_cat, status, status_cat, age, time, ph.ecog, ph.karno) 
cancer %>% summarize(count = n()) 

#MANOVA
man1 <- manova(cbind(age, time, ph.ecog, ph.karno)~status_cat, data=cancer)
summary(man1) 
summary.aov(man1) #ANOVA
#t tests
pairwise.t.test(cancer$ph.karno, cancer$status_cat, p.adj = "none")
pairwise.t.test(cancer$ph.ecog, cancer$status_cat, p.adj = "none")
.05/(1+4+2) #bonferroni adjustment is 0.0056 (1 MANOVA, 4 ANOVAs, 2 t tests)
1-((.95)^7) #type I error
```
  
There were 7 total tests (1 MANOVA, 4 ANOVAs, 2 t tests) conducted, resulting in a probability of 0.3017 for at least one type I error. Thus, the adjusted alpha or the bonferroni correction is 0.0071 after adjusting for multiple comparisons.

According to the MANOVA, for at least one of the dependent variables, at least one of the statuses mean were significantly different (p-value (0.0011) less than the alpha). Since the MANOVA resulted in a significant difference, univariate ANOVAs were run on each dependent variable. According to the univariate ANOVAs, there is significant evidence that shows that for the ph.ecog and the ph.karno variable, at least one species mean differs after adjusting for multiple comparisons (p-values (0.0005 and 0.0070 respectively) less than the alpha). The post hoc analysis showed that both statuses were found to differ signficantly from each other in terms of the ph.karno variable after adjusting for multiple comparisons (p-value (0.0070) less than the alpha). Likewise, both statuses were also found to differ significantly in terms of the ph.ecog variable after adjustment (p-value (0.0005) less than the alpha).


```{r}
#multivariate normality assumption
ggplot(cancer, aes(x=age, y=time)) + geom_point(alpha = .5) +geom_density_2d(h=2)  +facet_wrap(~status_cat)
ggplot(cancer, aes(x=ph.ecog, y=ph.karno)) + geom_point(alpha = .5) +geom_density_2d(h=2)  +facet_wrap(~status_cat)
#homogeneity of (co)variances assumption
covmats <- cancer %>% select(age, time, ph.ecog, ph.karno, status_cat) %>%
  group_by(status_cat) %>% do(covs=cov(.[1:4])) 
for(i in 1:2){print(as.character(covmats$status_cat[i])); print(covmats$covs[i])}
```

From looking at my multivariate plots, it looks like the assumption of multivariate normality was not met. Likewise, the assumption of homogeneity of (co)variances does not look like it has been met since the values for the censored and dead statuses differ greatly.



#2. Randomization Test
```{r}
#H0: mean survival times are the same for censored vs. dead status
#Ha: mean survival times are different for censored vs. dead status
data1 <- data.frame(status_cat=cancer$status_cat,time = cancer$time)
ggplot(data1, aes(time, fill=status_cat)) + geom_histogram(bins=6) + facet_wrap(~status_cat, ncol=2) 
data1 %>% group_by(status_cat) %>% summarize(means=mean(time)) %>% 
  summarize(`mean_diff`=diff(means)) #actual mean difference or observed test statistic
```

The null hypothesis is that the mean survival times are the same for censored vs. dead statuses. The alternative hypothesis is that the survival times are different for censored vs. dead statuses. A histogram was created in order to show the distribution of survival times for each status. The actual mean difference was calculated to be -78.06768 days.

```{r}
#randomization test
rand_dist<-vector()
for(i in 1:5000){ 
  new<-data.frame(time=sample(data1$time), status_cat=data1$status_cat)
  rand_dist[i]<- mean(new[new$status_cat=="censored",]$time) - 
    mean(new[new$status=="dead",]$time)}
mean(rand_dist< -78.06768 | rand_dist> 78.06768 ) #two-tailed p-value
{hist(rand_dist,main="",ylab=""); abline(v = c(-78.06768, 78.06768)  ,col="red")}
t.test(data=data1, time~status_cat)
```
 
After running the randomization test, the two-tailed p-value (0.0106) was found to be less than the alpha, indicating that I should reject the null hypothesis. This p-value corresponds with the probability of observing a mean difference as extreme as the actual mean difference in this randomization distribution and is illustrated by the histogram. I then conducted a t test for comparison, resulting in a p-value of 0.0166, also reinforcing that I should reject the null. 

#3. Linear Regression
```{r}
cancer <- cancer %>% mutate(age_c= age - mean(age)) #mean-centering
fit1 <- lm(time ~ age_c*status_cat, data = cancer)
summary(fit1)
#regression plot
cancer %>% ggplot(aes(age_c, time, color=status_cat)) + 
  geom_point(aes(color=status_cat)) + geom_smooth(method = "lm", se=F)
```

The predicted survival time is 362.5057 days for a patient with a censored status and an average age. Patients with a censored status show a decrease of 0.4327 days in survival time for every 1 year increase in age on average. For patients with an average age, survival time is 75.6575 days lower for dead patients than censored patients. The slope for age on survival time is 1.2744 lesser for dead patients compared to censored patients. There is also a regression plot that showcases the best-fitting line.

```{r}
#linearity 
resids <- fit1$residuals
fitvals <- fit1$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='red')
#normality
shapiro.test(resids)
#homoskedasticity
library(sandwich)
library(lmtest)
bptest(fit1)
```

For the linearity assumption, the residual v. fitted values plot showcases if there is linearity. Since there was a gap between the 325 and 350 fitted value marks indicating that the data points are not randomly dispersed, it is most likely that the linearity assumption was not met. For the normality assumption, the p-value (4.02e-11) from the Shapiro-Wilk test was less than the alpha, indicating that I should reject the null hypothesis of normality. Therefore, the normality assumption was also not met. For the homoskedasticity assumption, the Breusch-Pagan test was run and resulted in a p-value (0.7745) greater than the alpha, resulting in a failure to reject the null hypothesis of homoskedasticity. Therefore, the homoskedasticity assumption was met.

``` {r}
#robust SEs
coeftest(fit1, vcov = vcovHC(fit1))
```

For patients with an average age, survival time is 75.6570 days lower for dead patients compared to censored patients (significant effect, t=-2.2113, p-value = 0.02803). The effect of age by itself and the interaction between age and status were not significant (p-values were greater than the alpha) effects on survival time. Therefore, there were no changes after accounting for robust standard errors as the censoring status was the only significant effect for both linear regressions with uncorrected standard errors and robust standard errors.

``` {r}
#explaining variation
(summary(fit1)$r.sq)*100
```

The model explains 3.1484% of the variation in the outcome. This low value indicates that there may be other factors or variables that can explain the variation that were not included in this model.



#4. Bootstrapped SEs
``` {r}
boot_dat<- sample_frac(cancer, replace=T)
samp_distn<-replicate(5000, {
  boot_dat <- sample_frac(cancer, replace=T) 
  fit2 <- lm(time ~ age_c*status_cat,  data=boot_dat) 
  coef(fit2) 
})
#estimated SEs
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)
```

The bootstrapped standard errors have very slightly decreased when compared to the robust standard errors but have very slightly increased when compared to the original standard errors. An increased standard error would indicate a decreased t-statistic and thus an increased p-value. Oppositely, a decreased standard error would indicate an increased t-statistic and a decreased p-value. However, since the bootstrapped standard errors are between the narrow range of the original and robust standard errors, there is likely no significant change in the p-values. Thus, I would still likely find that the only significant effect on survival time would be the censoring status of a patient of average age. 



#5. Logistic Regression
``` {r}
fit3 <- glm(status ~ time + ph.karno + sex_cat, data = cancer, family = "binomial")
summary(fit3)
exp(coef(fit3))
prob2 <- predict(fit3, type = "response")
pred2 <- ifelse(prob2>.5,1,0)
```

Controlling for ph.karno scores and sex, for every one additional day in survival time, odds of status increase by a factor of 0.9987 (not significant, p-value = 0.0734). Controlling for time and sex, for every one additional point in ph.karno score, odds of status increase by a factor of 0.9661 (significant, p-value of 0.0132). Controlling for time and ph.karno scores, odds of status for males is 2.8952 times odds of status for females (significant effect, p-value = 0.0007).

``` {r}
#confusion matrix
table(prediction=pred2, truth=cancer$status) %>% addmargins
(12+154)/226 #accuracy (acc)
154/163 #sensitivity (tpr)
12/63 #specificity (tnr)
154/205 #precision (ppv)
```

The confusion matrix is computed above. There is an accuracy of 0.7345 of correctly identified statuses. The sensitivity is 0.9448, indicating a high probability of correctly identifying a dead patient. The specificity of 0.1905 showcases the probability of a censored status for a censored patient. The precision is 0.7512, and is the proportion of those classified as dead who actually are dead.

``` {r}
#density plot
cancer$logit<-predict(fit3,type="link") 
cancer %>% ggplot() + geom_density(aes(logit,color=status_cat,fill=status_cat), alpha=.4)+
  theme() + geom_vline(xintercept=0) + xlab("logit (log-odds)") +
  geom_rug(aes(logit,color=status_cat))

#ROC plot and AUC
library(plotROC)
ROCplot <- ggplot(cancer) + geom_roc(aes(d=status, m =prob2), n.cuts = 0)
ROCplot
calc_auc(ROCplot)
```

The density plot showcases the proportions that were correctly classified. The gray overlapping area is the proportion of the predicted log-odds that have been misclassified. The AUC of the ROC plot is 0.7086, which indicates that the model is fair for predicting status from survival time, ph. karno scores, and sex.

```{r}
class_diag<-function(probs,truth){
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  data.frame(acc,sens,spec,ppv,auc)
}

#10-fold CV
set.seed(1234)
k=10
data2<-cancer[sample(nrow(cancer)),] 
folds<-cut(seq(1:nrow(cancer)),breaks=k,labels=F) 
diags<-NULL
for(i in 1:k){          
  train<-data2[folds!=i,] 
  test<-data2[folds==i,]
  truth<-test$status
  fit3<- glm(status ~ time + ph.karno + sex_cat, data=train)
  probs<- predict(fit3, newdata=test)
  diags<-rbind(diags, class_diag(probs,truth))
}
summarize_all(diags,mean)
```

The out-of-sample accuracy, sensitivity, and recall are 0.7113, 0.9469, and 0.7359 respectively. The out-of-sample AUC from the CV was also 0.7007. There was not much change between the out-of-sample class diagnostics and the in-sample class diagnostics, indicating that the original model was probably not overfitting.



#6. LASSO regression
```{r}
library(glmnet)
cancer1 <- cancer %>% select(-status_cat, -logit, -age_c)
view(cancer1)
y <- as.matrix(cancer1$status)
x <- model.matrix(status~., data=cancer1)[,-1]
cv<-cv.glmnet(x,y,family="binomial") 
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.1se) 
coef(lasso)

set.seed(1234) 
k=10
data3 <- cancer1 %>% sample_frac 
folds <- ntile(1:nrow(data3),n=10)

diags<-NULL 
for(i in 1:k){
  train <- data3[folds!=i,] 
  test <- data3[folds==i,] 
  truth <- test$status 
  
  fit4 <- glm(status~ ph.ecog, data=train, family="binomial")
  probs <- predict(fit4, newdata=test, type="response") 
  diags<-rbind(diags,class_diag(probs,truth))
} 
diags%>%summarize_all(mean)
```
The status_cat variable was removed since it was the categorical version of the binary response variable and interfered with the LASSO results. Similarily, the logit and age_c variables were removed as they were created for the other regression models and also interferred with the LASSO regression.  

The ph.ecog variable was found to be the most important predictor for patient censoring status. Therefore, the ph.ecog variable was used as the only predictor for status and was used to run class diagnositics under CV. The AUC from the LASSO regression was 0.6301. Compared to the out-of-sample AUC of 0.7001 from the logistic regression, the worse performance indicates that the model was actually overfitting.